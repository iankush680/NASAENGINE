{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# AeroGuard RUL - Jet Engine Health Monitoring\n",
                "\n",
                "CNN-LSTM model for Remaining Useful Life prediction using NASA C-MAPSS FD001 dataset."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment and run if packages are not installed\n",
                "# !pip install pandas numpy tensorflow scikit-learn matplotlib plotly"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "\n",
                "print(f\"TensorFlow version: {tf.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset path\n",
                "DATA_DIR = '../datasets/CMAPSSData'\n",
                "MODEL_DIR = '../models'\n",
                "\n",
                "# Column names\n",
                "COLUMN_NAMES = ['unit', 'time'] + [f'op{i}' for i in range(1, 4)] + [f'sensor{i}' for i in range(1, 22)]\n",
                "\n",
                "# Sensors to drop (constant values)\n",
                "SENSORS_TO_DROP = ['sensor1', 'sensor5', 'sensor10', 'sensor16', 'sensor18', 'sensor19', 'op3']\n",
                "\n",
                "# Hyperparameters\n",
                "MAX_RUL_CAP = 125\n",
                "SEQUENCE_LENGTH = 30\n",
                "EPOCHS = 100\n",
                "BATCH_SIZE = 256\n",
                "\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load datasets\n",
                "train_df = pd.read_csv(f'{DATA_DIR}/train_FD001.txt', sep=r'\\s+', header=None, names=COLUMN_NAMES)\n",
                "test_df = pd.read_csv(f'{DATA_DIR}/test_FD001.txt', sep=r'\\s+', header=None, names=COLUMN_NAMES)\n",
                "rul_df = pd.read_csv(f'{DATA_DIR}/RUL_FD001.txt', header=None, names=['RUL'])\n",
                "\n",
                "print(f\"Training data: {train_df.shape}\")\n",
                "print(f\"Test data: {test_df.shape}\")\n",
                "print(f\"RUL labels: {rul_df.shape}\")\n",
                "train_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def add_rul_labels(df, max_rul_cap=MAX_RUL_CAP):\n",
                "    \"\"\"Add RUL labels with piecewise linear capping.\"\"\"\n",
                "    df = df.copy()\n",
                "    rul_list = []\n",
                "    for unit in df['unit'].unique():\n",
                "        unit_df = df[df['unit'] == unit]\n",
                "        max_cycle = unit_df['time'].max()\n",
                "        rul = max_cycle - unit_df['time']\n",
                "        rul_list.extend(rul.tolist())\n",
                "    df['RUL'] = rul_list\n",
                "    df['RUL'] = df['RUL'].clip(upper=max_rul_cap)\n",
                "    return df\n",
                "\n",
                "# Add RUL labels to training data\n",
                "train_df = add_rul_labels(train_df)\n",
                "print(\"RUL distribution:\")\n",
                "train_df['RUL'].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Drop constant sensors\n",
                "cols_to_drop = [col for col in SENSORS_TO_DROP if col in train_df.columns]\n",
                "train_df = train_df.drop(columns=cols_to_drop)\n",
                "test_df = test_df.drop(columns=cols_to_drop)\n",
                "\n",
                "print(f\"Remaining columns: {list(train_df.columns)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature columns\n",
                "feature_cols = [col for col in train_df.columns if col.startswith('sensor') or col.startswith('op')]\n",
                "print(f\"Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
                "\n",
                "# Normalize data\n",
                "scaler = MinMaxScaler()\n",
                "train_df[feature_cols] = scaler.fit_transform(train_df[feature_cols])\n",
                "test_df[feature_cols] = scaler.transform(test_df[feature_cols])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_sequences(df, sequence_length, is_test=False):\n",
                "    \"\"\"Create 3D sequences for CNN-LSTM.\"\"\"\n",
                "    sequences, labels, engine_ids = [], [], []\n",
                "    \n",
                "    for unit in df['unit'].unique():\n",
                "        unit_df = df[df['unit'] == unit].sort_values('time')\n",
                "        data = unit_df[feature_cols].values\n",
                "        \n",
                "        if is_test:\n",
                "            if len(data) >= sequence_length:\n",
                "                sequences.append(data[-sequence_length:])\n",
                "                engine_ids.append(unit)\n",
                "        else:\n",
                "            rul_values = unit_df['RUL'].values\n",
                "            for i in range(len(data) - sequence_length + 1):\n",
                "                sequences.append(data[i:i + sequence_length])\n",
                "                labels.append(rul_values[i + sequence_length - 1])\n",
                "                engine_ids.append(unit)\n",
                "    \n",
                "    X = np.array(sequences)\n",
                "    if is_test:\n",
                "        return X, np.array(engine_ids)\n",
                "    return X, np.array(labels), np.array(engine_ids)\n",
                "\n",
                "# Create sequences\n",
                "X_train, y_train, train_ids = create_sequences(train_df, SEQUENCE_LENGTH, is_test=False)\n",
                "X_test, test_ids = create_sequences(test_df, SEQUENCE_LENGTH, is_test=True)\n",
                "y_test = rul_df['RUL'].values\n",
                "\n",
                "print(f\"X_train shape: {X_train.shape}\")\n",
                "print(f\"y_train shape: {y_train.shape}\")\n",
                "print(f\"X_test shape: {X_test.shape}\")\n",
                "print(f\"y_test shape: {y_test.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train/validation split\n",
                "val_split = int(0.8 * len(X_train))\n",
                "X_val, y_val = X_train[val_split:], y_train[val_split:]\n",
                "X_train, y_train = X_train[:val_split], y_train[:val_split]\n",
                "\n",
                "print(f\"Training samples: {len(X_train)}\")\n",
                "print(f\"Validation samples: {len(X_val)}\")\n",
                "print(f\"Test samples: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build CNN-LSTM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_model(input_shape):\n",
                "    \"\"\"Build CNN-LSTM hybrid architecture.\"\"\"\n",
                "    model = Sequential([\n",
                "        # CNN for spatial features\n",
                "        Conv1D(filters=64, kernel_size=3, activation='relu', \n",
                "               input_shape=input_shape, padding='same'),\n",
                "        MaxPooling1D(pool_size=2),\n",
                "        \n",
                "        # LSTM for temporal patterns\n",
                "        LSTM(100, return_sequences=True),\n",
                "        Dropout(0.2),\n",
                "        LSTM(50),\n",
                "        Dropout(0.2),\n",
                "        \n",
                "        # Output\n",
                "        Dense(1, activation='linear')\n",
                "    ])\n",
                "    \n",
                "    model.compile(\n",
                "        optimizer=Adam(learning_rate=0.001),\n",
                "        loss='mse',\n",
                "        metrics=['mae']\n",
                "    )\n",
                "    return model\n",
                "\n",
                "model = build_model((X_train.shape[1], X_train.shape[2]))\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "callbacks = [\n",
                "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
                "    ModelCheckpoint(f'{MODEL_DIR}/cnn_lstm_model.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
                "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
                "]\n",
                "\n",
                "history = model.fit(\n",
                "    X_train, y_train,\n",
                "    validation_data=(X_val, y_val),\n",
                "    epochs=EPOCHS,\n",
                "    batch_size=BATCH_SIZE,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss\n",
                "axes[0].plot(history.history['loss'], label='Training Loss')\n",
                "axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
                "axes[0].set_title('Model Loss')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Loss (MSE)')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True)\n",
                "\n",
                "# MAE\n",
                "axes[1].plot(history.history['mae'], label='Training MAE')\n",
                "axes[1].plot(history.history['val_mae'], label='Validation MAE')\n",
                "axes[1].set_title('Model MAE')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('MAE')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_rmse(y_true, y_pred):\n",
                "    \"\"\"Calculate RMSE.\"\"\"\n",
                "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
                "\n",
                "def calculate_score(y_true, y_pred):\n",
                "    \"\"\"Calculate NASA S-Score.\"\"\"\n",
                "    d = y_pred - y_true\n",
                "    score = 0\n",
                "    for di in d:\n",
                "        if di < 0:\n",
                "            score += np.exp(-di / 13) - 1\n",
                "        else:\n",
                "            score += np.exp(di / 10) - 1\n",
                "    return score\n",
                "\n",
                "# Predict\n",
                "y_pred = model.predict(X_test, verbose=0).flatten()\n",
                "y_pred = np.maximum(y_pred, 0)  # Non-negative\n",
                "\n",
                "# Metrics\n",
                "rmse = calculate_rmse(y_test, y_pred)\n",
                "score = calculate_score(y_test, y_pred)\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"EVALUATION RESULTS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"Test RMSE: {rmse:.4f}\")\n",
                "print(f\"Test S-Score: {score:.4f}\")\n",
                "print(\"=\" * 50)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predictions vs Actual\n",
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.scatter(y_test, y_pred, alpha=0.5, edgecolors='k')\n",
                "plt.plot([0, max(y_test)], [0, max(y_test)], 'r--', label='Perfect')\n",
                "plt.xlabel('True RUL')\n",
                "plt.ylabel('Predicted RUL')\n",
                "plt.title('True vs Predicted RUL')\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "errors = y_pred - y_test\n",
                "plt.hist(errors, bins=30, edgecolor='k', alpha=0.7)\n",
                "plt.axvline(x=0, color='r', linestyle='--')\n",
                "plt.xlabel('Prediction Error')\n",
                "plt.ylabel('Frequency')\n",
                "plt.title('Error Distribution')\n",
                "plt.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Sample Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Show predictions for first 20 engines\n",
                "results_df = pd.DataFrame({\n",
                "    'Engine ID': test_ids[:20].astype(int),\n",
                "    'True RUL': y_test[:20].astype(int),\n",
                "    'Predicted RUL': np.round(y_pred[:20]).astype(int),\n",
                "    'Error': np.round(y_pred[:20] - y_test[:20]).astype(int)\n",
                "})\n",
                "\n",
                "def health_status(rul):\n",
                "    health_pct = min(100, max(0, (rul / 125) * 100))\n",
                "    if health_pct > 70:\n",
                "        return 'SAFE'\n",
                "    elif health_pct > 30:\n",
                "        return 'MAINTENANCE DUE'\n",
                "    return 'CRITICAL'\n",
                "\n",
                "results_df['Status'] = results_df['Predicted RUL'].apply(health_status)\n",
                "results_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Health Status Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Color-coded predictions\n",
                "colors = []\n",
                "for pred in y_pred:\n",
                "    health_pct = (pred / 125) * 100\n",
                "    if health_pct > 70:\n",
                "        colors.append('green')\n",
                "    elif health_pct > 30:\n",
                "        colors.append('orange')\n",
                "    else:\n",
                "        colors.append('red')\n",
                "\n",
                "plt.figure(figsize=(14, 6))\n",
                "plt.bar(range(len(y_pred)), y_pred, color=colors, edgecolor='k', alpha=0.7)\n",
                "plt.axhline(y=87.5, color='green', linestyle='--', label='Safe (>70%)')\n",
                "plt.axhline(y=37.5, color='orange', linestyle='--', label='Maintenance (30-70%)')\n",
                "plt.xlabel('Engine Index')\n",
                "plt.ylabel('Predicted RUL (cycles)')\n",
                "plt.title('Engine Health Status - All Test Engines')\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print(f\"\\nHealth Distribution:\")\n",
                "print(f\"  Safe (Green): {colors.count('green')} engines\")\n",
                "print(f\"  Maintenance (Orange): {colors.count('orange')} engines\")\n",
                "print(f\"  Critical (Red): {colors.count('red')} engines\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}